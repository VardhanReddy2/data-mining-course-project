# -*- coding: utf-8 -*-
"""Diabetic_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TSH-ok9hbBqamFavlwBnWdoeu-qLSU-U

# **Diabetic Prediction**

**Aim:** Making Diabetic Prediction using:-

* Random Forest Classifier model
* Support Vector Machine (SVM) model - Linear Kernel, RBF & poly
* Logistic Regression model
* K Nearest Neighbour (KNN) model
* Decision Tree Classifier model
* Naive Bayes Model
* XGBoost Classifier Model

& finding the best accuracy.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import math
import pandas as pd
import seaborn as sns
import plotly.express as px
import pickle
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn import tree
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.metrics import classification_report
# %matplotlib inline

# Loading data
df=pd.read_csv('diabetes2.csv')

df_temp = df.copy()

# Viewing First Five rows
df.head()

df.info()

df.shape

df["Outcome"].value_counts()

df.isnull().sum()

# Visualizing outcome
sns.catplot(x="Outcome", kind="count", data=df_temp, palette="Set2")
plt.show()

# Visualizing Number of Diabetics and Non Diabetics patient of different age group
ax = sns.catplot(x="Age", kind="count",hue="Outcome",data=df_temp, palette="pastel", legend=False)
ax.fig.set_figwidth(20)
plt.legend(loc='upper right', labels= ["Non diabetic", "Diabetic"])
plt.show()

# Age Distribution
fig = px.histogram(df, x="Age",
                   marginal="box")
fig.show()

# Age Distribution for outcome 0
fig = px.histogram(df, x=df[df.Outcome==0].Age,
                   marginal="box",
                   color_discrete_sequence=['lightgreen'])
fig.show()

# Age Distribution for outcome 1
fig = px.histogram(df, x=df[df.Outcome==1].Age,
                   marginal="box",
                   color_discrete_sequence=['purple'])
fig.show()

# Glucose Distribution for outcome 1
fig = px.histogram(df, x=df[df.Outcome==1].Glucose,
                   marginal="box",
                   color_discrete_sequence=['#AB63FA'])
fig.show()

# Average Glucose for Diabetics Patient
df[df.Outcome==1].Glucose.mean()

x = df_temp.drop(['Outcome'], axis = 1)
y = df_temp.loc[:,"Outcome"].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 123)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

"""### **Random Forest Classifier**"""

model1 = RandomForestClassifier(n_estimators = 100)
model1.fit(x_train, y_train)
pickle.dump(model1, open('random_forest_model.pkl', 'wb'))

x_pred = model1.predict(x_train)

confusion_matrix(y_train, x_pred)

score = accuracy_score(y_train, x_pred)
print("Training accuracy" ,score)

y_pred = model1.predict(x_test)

confusion_matrix(y_pred,y_test)

score = accuracy_score(y_pred, y_test)
print("Testing accuracy",score)

cm1 = confusion_matrix(y_test, y_pred)
sns.heatmap(cm1, annot=True, fmt=".0f")
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Accuracy Score: {0}'.format(score), size = 15)
plt.show()

print('Precision: %.3f' % precision_score(y_test, y_pred))
print('Recall: %.3f' % recall_score(y_test, y_pred))
print('F1 Score: %.3f' % f1_score(y_test, y_pred))

"""### **Support Vector Machine (SVM)**

##### **SVM** - Linear Kernel
"""

model2 = svm.SVC(kernel = 'linear', random_state = 0, C=1.0)
model2.fit(x_train, y_train)
pickle.dump(model2, open('svm_linear_model.pkl', 'wb'))

x_pred = model2.predict(x_train)

confusion_matrix(y_train, x_pred)

score = accuracy_score(y_train, x_pred)
print("Training accuracy" ,score)

y_pred = model2.predict(x_test)

confusion_matrix(y_pred,y_test)

score = accuracy_score(y_pred, y_test)
print("Testing accuracy",score)

cm2 = confusion_matrix(y_test, y_pred)
sns.heatmap(cm2, annot=True, fmt=".0f")
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Accuracy Score: {0}'.format(score), size = 15)
plt.show()

print('Precision: %.3f' % precision_score(y_test, y_pred))
print('Recall: %.3f' % recall_score(y_test, y_pred))
print('F1 Score: %.3f' % f1_score(y_test, y_pred))

"""##### **SVM** - RBF"""

model3 = svm.SVC(kernel = 'rbf', random_state = 0, C=1.0)
model3.fit(x_train, y_train)
pickle.dump(model3, open('svm_rbf_model.pkl', 'wb'))

x_pred = model3.predict(x_train)

confusion_matrix(y_train, x_pred)

score = accuracy_score(y_train, x_pred)
print("Training accuracy" ,score)

y_pred = model3.predict(x_test)

confusion_matrix(y_pred,y_test)

score = accuracy_score(y_pred, y_test)
print("Testing accuracy",score)

cm3 = confusion_matrix(y_test, y_pred)
sns.heatmap(cm3, annot=True, fmt=".0f")
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Accuracy Score: {0}'.format(score), size = 15)
plt.show()

print('Precision: %.3f' % precision_score(y_test, y_pred))
print('Recall: %.3f' % recall_score(y_test, y_pred))
print('F1 Score: %.3f' % f1_score(y_test, y_pred))

"""##### **SVM** - poly"""

model4 = svm.SVC(kernel = 'poly', random_state = 0, C=1.0)
model4.fit(x_train, y_train)
pickle.dump(model4, open('svm_poly_model.pkl', 'wb'))

x_pred = model4.predict(x_train)

confusion_matrix(y_train, x_pred)

score = accuracy_score(y_train, x_pred)
print("Training accuracy" ,score)

y_pred = model4.predict(x_test)

confusion_matrix(y_pred,y_test)

score = accuracy_score(y_pred, y_test)
print("Testing accuracy",score)

cm4 = confusion_matrix(y_test, y_pred)
sns.heatmap(cm4, annot=True, fmt=".0f")
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Accuracy Score: {0}'.format(score), size = 15)
plt.show()

print('Precision: %.3f' % precision_score(y_test, y_pred))
print('Recall: %.3f' % recall_score(y_test, y_pred))
print('F1 Score: %.3f' % f1_score(y_test, y_pred))

"""### **Logistic Regression**"""

sc_x = StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)

model5 = LogisticRegression(random_state = 0)
model5.fit(x_train, y_train)
pickle.dump(model5, open('logistic_regression_model.pkl', 'wb'))


x_pred = model5.predict(x_train)

confusion_matrix(y_train, x_pred)

score = accuracy_score(y_train, x_pred)
print("Training accuracy" ,score)

y_pred = model5.predict(x_test)

confusion_matrix(y_pred,y_test)

score = accuracy_score(y_pred, y_test)
print("Testing accuracy",score)

cm5 = confusion_matrix(y_test, y_pred)
sns.heatmap(cm5, annot=True, fmt=".0f")
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Accuracy Score: {0}'.format(score), size = 15)
plt.show()

print('Precision: %.3f' % precision_score(y_test, y_pred))
print('Recall: %.3f' % recall_score(y_test, y_pred))
print('F1 Score: %.3f' % f1_score(y_test, y_pred))

"""### **K-Nearest Neighbour (KNN)**"""

model6 = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )
model6.fit(x_train, y_train)
pickle.dump(model6, open('knn_model.pkl', 'wb'))


x_pred = model6.predict(x_train)

confusion_matrix(y_train, x_pred)

score = accuracy_score(y_train, x_pred)
print("Training accuracy" ,score)

y_pred = model6.predict(x_test)

confusion_matrix(y_pred,y_test)

score = accuracy_score(y_pred, y_test)
print("Testing accuracy",score)

cm6 = confusion_matrix(y_test, y_pred)
sns.heatmap(cm6, annot=True, fmt=".0f")
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Accuracy Score: {0}'.format(score), size = 15)
plt.show()

print('Precision: %.3f' % precision_score(y_test, y_pred))
print('Recall: %.3f' % recall_score(y_test, y_pred))
print('F1 Score: %.3f' % f1_score(y_test, y_pred))

"""### **Decision Tree Classifier**"""

model7 = tree.DecisionTreeClassifier()
model7.fit(x_train, y_train)
pickle.dump(model7, open('decision_tree_model.pkl', 'wb'))


x_pred = model7.predict(x_train)
confusion_matrix(y_train, x_pred)

score = accuracy_score(y_train, x_pred)
print("Training accuracy" ,score)

y_pred = model7.predict(x_test)
confusion_matrix(y_pred,y_test)

score = accuracy_score(y_pred, y_test)
print("Testing accuracy",score)

cm7 = confusion_matrix(y_test, y_pred)
sns.heatmap(cm7, annot=True, fmt=".0f")
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Accuracy Score: {0}'.format(score), size = 15)
plt.show()

print('Precision: %.3f' % precision_score(y_test, y_pred))
print('Recall: %.3f' % recall_score(y_test, y_pred))
print('F1 Score: %.3f' % f1_score(y_test, y_pred))

"""### **Naive Bayes**"""

model8 = GaussianNB()
model8.fit(x_train, y_train)
pickle.dump(model8, open('naive_bayes_model.pkl', 'wb'))


x_pred = model8.predict(x_train)
confusion_matrix(y_train, x_pred)

score = accuracy_score(y_train, x_pred)
print("Training accuracy" ,score)

y_pred = model8.predict(x_test)
confusion_matrix(y_pred,y_test)

score = accuracy_score(y_pred, y_test)
print("Testing accuracy",score)

cm8 = confusion_matrix(y_test, y_pred)
sns.heatmap(cm8, annot=True, fmt=".0f")
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Accuracy Score: {0}'.format(score), size = 15)
plt.show()

print('Precision: %.3f' % precision_score(y_test, y_pred))
print('Recall: %.3f' % recall_score(y_test, y_pred))
print('F1 Score: %.3f' % f1_score(y_test, y_pred))

"""### **XGBoost Classifier**"""

model9 = XGBClassifier(n_estimators=100)
model9.fit(x_train, y_train)
pickle.dump(model9, open('xgboost_model.pkl', 'wb'))


x_pred = model9.predict(x_train)
confusion_matrix(y_train, x_pred)

score = accuracy_score(y_train, x_pred)
print("Training accuracy" ,score)

y_pred = model9.predict(x_test)
confusion_matrix(y_pred,y_test)

score = accuracy_score(y_pred, y_test)
print("Testing accuracy",score)

cm9 = confusion_matrix(y_test, y_pred)
sns.heatmap(cm9, annot=True, fmt=".0f")
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Accuracy Score: {0}'.format(score), size = 15)
plt.show()

print('Precision: %.3f' % precision_score(y_test, y_pred))
print('Recall: %.3f' % recall_score(y_test, y_pred))
print('F1 Score: %.3f' % f1_score(y_test, y_pred))




"""## **Conclusion**


The best accuracy obtained is 0.7913385826771654 using SVM-Linear Kernel model.


"""